import pandas as pd
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å CSV
df = pd.read_csv('winequality-red.csv', sep=';')
print("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:")
print(df.head(), "\n")
print("üìä ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û:")
print(df['quality'].value_counts().sort_index(), "\n")

# 2. ‡∏à‡∏±‡∏î label ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô classification ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
#    ‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û >=7 = 'good', else 'not good'
df['quality_label'] = df['quality'].apply(lambda x: 'good' if x >= 7 else 'not good')

# 3. ‡πÅ‡∏¢‡∏Å feature ‡πÅ‡∏•‡∏∞ label
X = df.drop(columns=['quality', 'quality_label'])
y = df['quality_label']

# 4. ‡πÅ‡∏ö‡πà‡∏á‡∏ä‡∏∏‡∏î train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42)

# 5. ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Decision Tree
clf = DecisionTreeClassifier(criterion='entropy', random_state=0)
clf.fit(X_train, y_train)

# 6. ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
acc = clf.score(X_test, y_test)
print(f"üéØ Accuracy ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•: {acc*100:.2f}%\n")

# 7. ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ
plt.figure(figsize=(16,10))
plot_tree(clf, filled=True, feature_names=X.columns, class_names=clf.classes_)
plt.title('üå≥ Decision Tree: Wine Quality (red wine)')
plt.show()

# 8. ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏é‡πÅ‡∏ö‡∏ö if-then
rules = export_text(clf, feature_names=list(X.columns))
print("üìú ‡∏Å‡∏é‡∏à‡∏≤‡∏Å‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ:")
print(rules)

# 9. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å)
sample = X.iloc[[0]]
pred = clf.predict(sample)
print(f"\nüîÆ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏£‡∏Å {sample.values.tolist()[0]} ‚Üí ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {pred[0]}")
